import React, { useRef, useEffect, useState } from 'react';
import * as faceapi from 'face-api.js';
import { chamCongService } from '../../services/chamCongService';

const FaceRecognition = ({ onRegisterFace, onCheckIn, mode, selectedEmployee, disabled = false }) => {
  const videoRef = useRef();
  const canvasRef = useRef();
  const intervalRef = useRef(null);
  const modeRef = useRef(mode);

  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [faceDetected, setFaceDetected] = useState(false);
  const [scanningProgress, setScanningProgress] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  const [errorMsg, setErrorMsg] = useState('');
  const [identifiedEmployee, setIdentifiedEmployee] = useState(null);

  useEffect(() => {
    modeRef.current = mode;
  }, [mode]);

  useEffect(() => {
    loadModels();
    return () => {
      stopVideo();
      if (intervalRef.current) clearInterval(intervalRef.current);
    };
  }, []);

  const loadModels = async () => {
    try {
      const MODEL_URL = process.env.PUBLIC_URL + '/models';
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL + '/tiny_face_detector'),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL + '/face_landmark_68'),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL + '/face_recognition'),
      ]);
      setIsModelLoaded(true);
      startVideo();
    } catch (error) {
      console.error('‚ùå L·ªói khi t·∫£i m√¥ h√¨nh:', error);
    }
  };

  const startVideo = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480 }
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    } catch (error) {
      console.error('‚ùå Kh√¥ng th·ªÉ truy c·∫≠p camera:', error);
    }
  };

  const stopVideo = () => {
    if (videoRef.current && videoRef.current.srcObject) {
      videoRef.current.srcObject.getTracks().forEach(track => track.stop());
    }
  };

  const convertErrorMessage = (raw) => {
    try {
      const parsed = typeof raw === 'string' ? JSON.parse(raw) : raw;
      if (parsed?.message?.includes('ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω')) {
        const match = parsed.message.match(/nh√¢n vi√™n: (.+)/);
        const name = match?.[1] || 'ng∆∞·ªùi kh√°c';
        return `Khu√¥n m·∫∑t n√†y ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω cho nh√¢n vi√™n "${name}". Vui l√≤ng th·ª≠ l·∫°i v·ªõi ng∆∞·ªùi kh√°c.`;
      }
      if (parsed?.message?.includes('Kh√¥ng t√¨m th·∫•y nh√¢n vi√™n ph√π h·ª£p')) {
        return 'Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t ph√π h·ª£p. Vui l√≤ng th·ª≠ l·∫°i.';
      }
      return parsed?.message || 'ƒê√£ x·∫£y ra l·ªói kh√¥ng x√°c ƒë·ªãnh.';
    } catch {
      // fallback khi kh√¥ng parse ƒë∆∞·ª£c
      if (typeof raw === 'string' && raw.includes('ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω')) {
        const match = raw.match(/nh√¢n vi√™n: (.+)/);
        const name = match?.[1] || 'ng∆∞·ªùi kh√°c';
        return `Khu√¥n m·∫∑t n√†y ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω cho nh√¢n vi√™n "${name}".`;
      }
      return 'ƒê√£ x·∫£y ra l·ªói. Vui l√≤ng th·ª≠ l·∫°i.';
    }
  };

  const handleVideoPlay = () => {
    if (!isModelLoaded || disabled) return;
    if (!videoRef.current || videoRef.current.readyState < 2) return; // ƒê·∫£m b·∫£o video ƒë√£ s·∫µn s√†ng

    const canvas = faceapi.createCanvasFromMedia(videoRef.current);
    canvasRef.current.innerHTML = '';
    canvasRef.current.appendChild(canvas);

    const displaySize = {
      width: videoRef.current.width,
      height: videoRef.current.height
    };
    faceapi.matchDimensions(canvas, displaySize);

    const detectFaces = async () => {
      if (!videoRef.current || disabled || isProcessing) return;

      const detections = await faceapi
        .detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      const resizedDetections = faceapi.resizeResults(detections, displaySize);
      const ctx = canvas.getContext('2d');
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      faceapi.draw.drawDetections(canvas, resizedDetections);
      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

      if (detections.length > 0) {
        setFaceDetected(true);
        
        // Nh·∫≠n di·ªán khu√¥n m·∫∑t ngay khi ph√°t hi·ªán
        if (modeRef.current === 'checkin' && !identifiedEmployee && !isProcessing) {
          const faceDescriptor = detections[0].descriptor;
          try {
            const result = await chamCongService.identifyFace({ face_descriptor: Array.from(faceDescriptor) });
            if (result.success && result.data.identified) {
              setIdentifiedEmployee(result.data.nhan_vien);
            }
          } catch (error) {
            console.error('‚ùå L·ªói nh·∫≠n di·ªán khu√¥n m·∫∑t:', error);
          }
        }

        setIsProcessing(true);

        setScanningProgress(prev => {
          const newProgress = Math.min(prev + 25, 100);

          if (newProgress >= 100 && prev < 100) {
            const faceDescriptor = detections[0].descriptor;

            setTimeout(async () => {
              try {
                setErrorMsg('');
                if (modeRef.current === 'register') {
                  await onRegisterFace?.(faceDescriptor);
                } else {
                  await onCheckIn?.(faceDescriptor);
                }
              } catch (error) {
                console.error('‚ùå L·ªói x·ª≠ l√Ω khu√¥n m·∫∑t:', error);
                const rawMsg = error?.message || error?.response?.data || 'L·ªói kh√¥ng x√°c ƒë·ªãnh.';
                const userFriendlyMsg = convertErrorMessage(rawMsg);
                setErrorMsg(userFriendlyMsg);
              } finally {
                setIsProcessing(false);
                setScanningProgress(0);
              }
            }, 500);
          } else {
            setIsProcessing(false);
          }

          return newProgress;
        });
      } else {
        setFaceDetected(false);
        setIdentifiedEmployee(null);
        setScanningProgress(0);
        setIsProcessing(false);
      }
    };

    if (intervalRef.current) clearInterval(intervalRef.current);
    intervalRef.current = setInterval(detectFaces, 1000);
  };

  return (
    <div
      style={{
        position: 'relative',
        width: 640,
        height: 480,
        background: '#fff',
        borderRadius: 20,
        border: `3px solid ${faceDetected ? '#28a745' : '#dc3545'}`,
        overflow: 'hidden',
        margin: '0 auto',
        boxShadow: '0 2px 12px rgba(0,0,0,0.08)',
        display: 'flex',
        justifyContent: 'center',
        alignItems: 'center'
      }}
    >
      <video
        ref={videoRef}
        width="640"
        height="480"
        autoPlay
        muted
        onPlay={handleVideoPlay}
        style={{
          borderRadius: '20px',
          width: '640px',
          height: '480px',
          objectFit: 'cover',
          background: '#fff',
          display: 'block'
        }}
      />
      <div
        ref={canvasRef}
        style={{
          position: 'absolute',
          top: 0,
          left: 0,
          width: '640px',
          height: '480px',
          pointerEvents: 'none'
        }}
      />

      <div style={{
        position: 'absolute',
        top: '10px',
        left: '10px',
        backgroundColor: 'rgba(0,0,0,0.7)',
        color: 'white',
        padding: '5px 10px',
        borderRadius: '5px',
        fontSize: '12px'
      }}>
        {!isModelLoaded ? '‚è≥ ƒêang t·∫£i m√¥ h√¨nh...' :
         disabled ? '‚è∏Ô∏è T·∫°m d·ª´ng' :
         faceDetected ? '‚úÖ ƒê√£ ph√°t hi·ªán khu√¥n m·∫∑t' : '‚ùå Kh√¥ng ph√°t hi·ªán'}
      </div>

      {identifiedEmployee && (
        <div style={{
          position: 'absolute',
          top: '10px',
          right: '10px',
          backgroundColor: 'rgba(40, 167, 69, 0.9)',
          color: 'white',
          padding: '8px 12px',
          borderRadius: '8px',
          fontSize: '14px',
          fontWeight: 'bold',
          maxWidth: '200px',
          textAlign: 'center'
        }}>
          üë§ {identifiedEmployee.ten}
          <br />
          <span style={{ fontSize: '12px', opacity: 0.9 }}>
            {identifiedEmployee.ma_nhan_vien}
          </span>
          {identifiedEmployee.confidence && (
            <div style={{ fontSize: '11px', marginTop: '2px' }}>
              ƒê·ªô tin c·∫≠y: {identifiedEmployee.confidence}%
            </div>
          )}
        </div>
      )}

      {scanningProgress > 0 && (
        <div style={{
          position: 'absolute',
          bottom: '10px',
          left: '10px',
          right: '10px',
          backgroundColor: 'rgba(0,0,0,0.7)',
          borderRadius: '10px',
          padding: '5px'
        }}>
          <div style={{
            width: `${scanningProgress}%`,
            height: '10px',
            backgroundColor: '#28a745',
            borderRadius: '5px',
            transition: 'width 0.3s ease'
          }} />
          <div style={{
            color: 'white',
            textAlign: 'center',
            fontSize: '12px',
            marginTop: '2px'
          }}>
            {mode === 'register' ? 'ƒêang ƒëƒÉng k√Ω...' : 'ƒêang nh·∫≠n di·ªán...'} {scanningProgress}%
          </div>
        </div>
      )}

      {errorMsg && (
        <div style={{
          position: 'absolute',
          bottom: '60px',
          left: '10px',
          right: '10px',
          backgroundColor: '#dc3545',
          color: 'white',
          padding: '6px 10px',
          borderRadius: '6px',
          fontSize: '13px',
          textAlign: 'center'
        }}>
          ‚ö†Ô∏è {errorMsg}
        </div>
      )}
    </div>
  );
};

export default FaceRecognition;
